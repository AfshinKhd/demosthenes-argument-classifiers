# YAML configuration for a Distil-Bert Model
MODEL:
  name: "distilbert"  
  suffix: ""
  num_output: 3  # Number of output for classification 
  model_id: "xlm-roberta-base"
  train_size: .8
  max_len: 128
  train_batch_size: 4
  valid_batch_size: 4
  learning_rate: 1e-05
  epochs: 1  

train_params:
  batch_size: 4
  shuffle': True
  num_workers': 0
                    

test_params:
  batch_size: 4
  shuffle: True
  num_workers: 0
                    

# data:
#   data_path: "data/dataset.csv"  # Path to the dataset file
#   num_classes: 10  # Number of classes in the dataset

# evaluation:
#   metric: "accuracy"