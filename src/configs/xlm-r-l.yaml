# YAML configuration for a Distil-Bert Model
MODEL:
  name: "xlm-r"  
  suffix: "large"
  model_id: "xlm-roberta-large"
  train_size: .8
  max_len: 128
  train_batch_size: 4
  valid_batch_size: 4
  learning_rate: 1e-05
  epochs: 1  

train_params:
  batch_size: 4
  shuffle': True
  num_workers': 0
                    

test_params:
  batch_size: 4
  shuffle: True
  num_workers: 0
                    

