# YAML configuration 
MODEL:
  name: "deberta"  
  suffix: "v2-xlarge"
  num_pre_output: 1536 # Number of pre last layer output for classification 
  model_id: "microsoft/deberta-v2-xlarge"
  train_size: .8
  max_len: 128
  train_batch_size: 4
  valid_batch_size: 4
  learning_rate: 1.0e-05
  epochs: 1  

train_params:
  batch_size: 4
  shuffle: True
  num_workers: 0
                    

test_params:
  batch_size: 4
  shuffle: True
  num_workers: 0
                    

