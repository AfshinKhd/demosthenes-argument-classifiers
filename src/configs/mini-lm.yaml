# YAML configuration 
MODEL:
  name: "mini-lm"  
  suffix: ""
  num_pre_output: 384  # Number of pre last layer output for classification 
  model_id: "sentence-transformers/all-MiniLM-L12-v2"
  train_size: .8
  max_len: 128
  train_batch_size: 4
  valid_batch_size: 4
  learning_rate: 1.0e-05
  epochs: 6

train_params:
  batch_size: 4
  shuffle: True
  num_workers: 0
                    

test_params:
  batch_size: 4
  shuffle: True
  num_workers: 0
